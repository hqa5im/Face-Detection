{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 21:33:41.924850: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limiting GPU Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Images Into TensorFlow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = tf.data.Dataset.list_files('/Users/hannaqasim/Desktop/Face Detection J/data/pictures/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pic(file_path):\n",
    "    b_img = tf.io.read_file(file_path)\n",
    "    l_img = tf.io.decode_jpeg(b_img)\n",
    "    return l_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = pics.map(load_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:53:02.936811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [122]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-09 15:53:02.936998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [122]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [203, 196, 170],\n",
       "        [203, 196, 170],\n",
       "        [203, 196, 170]],\n",
       "\n",
       "       [[254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [203, 196, 170],\n",
       "        [203, 196, 170],\n",
       "        [203, 196, 170]],\n",
       "\n",
       "       [[254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [204, 197, 171],\n",
       "        [204, 197, 171],\n",
       "        [204, 197, 171]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [ 99,  40,  42],\n",
       "        [ 99,  40,  42],\n",
       "        [ 99,  40,  42]],\n",
       "\n",
       "       [[254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [ 99,  40,  42],\n",
       "        [100,  40,  42],\n",
       "        [100,  40,  42]],\n",
       "\n",
       "       [[254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [ 99,  40,  42],\n",
       "        [100,  40,  42],\n",
       "        [100,  40,  42]]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pics.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributing Data Amongst The Test, Train and Val Folders\n",
    "\n",
    "-> Run image_distribution.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2 as cv\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up augmentation pipeline using alb\n",
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=450, height=450),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='albumentations', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building and running the augmentation pipeline\n",
    "# adpated from nicknochnack\n",
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'pictures')):\n",
    "        img = cv.imread(os.path.join('data', partition, 'pictures', image))\n",
    "        \n",
    "        if (isinstance(img, np.ndarray)):\n",
    "            height, width, channel = img.shape\n",
    "        else:\n",
    "            None\n",
    "\n",
    "        coords = [0,0,0,0]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "            \n",
    "            # updates the coords list with the respective coordinates of the label\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            # normalizes the coordinates by dividing each coordinate by its corresponding dimension of the image\n",
    "            coords = list(np.divide(coords, [width, height, width, height]))\n",
    "\n",
    "        try: \n",
    "            # performs data augmentation on the current image and its annotation each time.\n",
    "            for x in range(40):\n",
    "                transformed = transform(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv.imwrite(os.path.join('augmented_data', partition, 'pictures', f'{image.split(\".\")[0]}.{x}.jpg'), transformed['image'])\n",
    "                \n",
    "                # initializes an empty dictionary that will contain the annotation information for the augmented image.\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                # if label file exists so face most likely exists\n",
    "                if os.path.exists(label_path):\n",
    "                    # if no faces detected\n",
    "                    if len(transformed['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                    # if face detected\n",
    "                        annotation['bbox'] = transformed['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                # if no label file exists and so no faces in picture\n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "                with open(os.path.join('augmented_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "                    \n",
    "        # if any error exists within the above code\n",
    "        except Exception as e:\n",
    "            None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading functions\n",
    "\n",
    "# image loading loading function\n",
    "def load_pic(file_path):\n",
    "    b_img = tf.io.read_file(file_path)\n",
    "    l_img = tf.io.decode_jpeg(b_img)\n",
    "    return l_img\n",
    "\n",
    "# label loading function\n",
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r') as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 21:34:43.444878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1760]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.99215686, 0.9490196 , 0.8627451 ],\n",
       "        [1.        , 0.95686275, 0.8784314 ],\n",
       "        [0.99607843, 0.95686275, 0.8509804 ],\n",
       "        ...,\n",
       "        [0.84705883, 0.8       , 0.7058824 ],\n",
       "        [0.84313726, 0.79607844, 0.7019608 ],\n",
       "        [0.84705883, 0.8       , 0.7137255 ]],\n",
       "\n",
       "       [[0.99607843, 0.9529412 , 0.8666667 ],\n",
       "        [0.99215686, 0.9490196 , 0.87058824],\n",
       "        [0.99215686, 0.94509804, 0.8509804 ],\n",
       "        ...,\n",
       "        [0.85490197, 0.80784315, 0.7137255 ],\n",
       "        [0.84705883, 0.8       , 0.7058824 ],\n",
       "        [0.84705883, 0.8       , 0.7137255 ]],\n",
       "\n",
       "       [[1.        , 0.95686275, 0.87058824],\n",
       "        [0.99607843, 0.94509804, 0.87058824],\n",
       "        [0.99215686, 0.94509804, 0.8509804 ],\n",
       "        ...,\n",
       "        [0.85882354, 0.8117647 , 0.7254902 ],\n",
       "        [0.85882354, 0.8117647 , 0.7254902 ],\n",
       "        [0.8509804 , 0.8039216 , 0.7176471 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.22745098, 0.24705882, 0.25882354],\n",
       "        [0.22352941, 0.23921569, 0.24313726],\n",
       "        [0.22352941, 0.23921569, 0.24313726],\n",
       "        ...,\n",
       "        [0.7882353 , 0.8039216 , 0.8       ],\n",
       "        [0.7372549 , 0.75686276, 0.7411765 ],\n",
       "        [0.7019608 , 0.70980394, 0.6901961 ]],\n",
       "\n",
       "       [[0.23137255, 0.2509804 , 0.2627451 ],\n",
       "        [0.21960784, 0.23921569, 0.2509804 ],\n",
       "        [0.21960784, 0.23529412, 0.23921569],\n",
       "        ...,\n",
       "        [0.8       , 0.80784315, 0.7882353 ],\n",
       "        [0.75686276, 0.76862746, 0.7411765 ],\n",
       "        [0.7137255 , 0.7254902 , 0.69803923]],\n",
       "\n",
       "       [[0.22352941, 0.24705882, 0.24705882],\n",
       "        [0.21960784, 0.23921569, 0.2509804 ],\n",
       "        [0.21176471, 0.23137255, 0.24313726],\n",
       "        ...,\n",
       "        [0.8235294 , 0.827451  , 0.8039216 ],\n",
       "        [0.7647059 , 0.7764706 , 0.7411765 ],\n",
       "        [0.7254902 , 0.73333335, 0.6901961 ]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading anad preprocessing images\n",
    "def load_and_preprocess_image(path):\n",
    "    images = tf.data.Dataset.list_files(path, shuffle=False)\n",
    "    images = images.map(load_pic)\n",
    "\n",
    "    images = images.map(lambda x: (tf.image.resize(x, (150,150)))/255)\n",
    "    return images\n",
    "\n",
    "train_images = load_and_preprocess_image('/Users/hannaqasim/Desktop/Face Detection J/augmented_data/train/pictures/*.jpg')\n",
    "test_images = load_and_preprocess_image('/Users/hannaqasim/Desktop/Face Detection J/augmented_data/test/pictures/*.jpg')\n",
    "val_images = load_and_preprocess_image('/Users/hannaqasim/Desktop/Face Detection J/augmented_data/val/pictures/*.jpg')\n",
    "\n",
    "train_images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 21:34:46.753355: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1760]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=uint8),\n",
       " array([0.    , 0.2183, 0.152 , 0.7773], dtype=float16))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and preprocess labels\n",
    "def load_and_preprocess_label(path):\n",
    "    labels = tf.data.Dataset.list_files(path, shuffle=False)\n",
    "\n",
    "    labels = labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n",
    "    return labels\n",
    "\n",
    "train_labels = load_and_preprocess_label('/Users/hannaqasim/Desktop/Face Detection J/augmented_data/train/labels/*.json')\n",
    "test_labels = load_and_preprocess_label('/Users/hannaqasim/Desktop/Face Detection J/augmented_data/test/labels/*.json')\n",
    "val_labels = load_and_preprocess_label('/Users/hannaqasim/Desktop/Face Detection J/augmented_data/val/labels/*.json')\n",
    "\n",
    "train_labels.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our final data set by combining images and labels\n",
    "\n",
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(3000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)\n",
    "\n",
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(1000)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)\n",
    "\n",
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(1000)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 21:34:51.959834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [1760]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-09 21:34:51.960142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [1760]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=uint8),\n",
       " array([[0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.767 , 0.8354, 1.    , 1.    ],\n",
       "        [0.452 , 0.177 , 0.7515, 0.5205],\n",
       "        [0.3994, 0.0639, 1.    , 1.    ],\n",
       "        [0.    , 0.    , 0.34  , 0.4802],\n",
       "        [0.    , 0.3455, 0.3547, 1.    ],\n",
       "        [0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.876 , 0.3613, 1.    , 0.708 ]], dtype=float16))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Using Functional API And Creating A Neutral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building my model\n",
    "\n",
    "def build_model():\n",
    "    # defining the input shape/layer of the images\n",
    "    input_shape = (150, 150, 3)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # adding convolutional layers to extract features from the input images\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    # flatten the output from the convolutional layers\n",
    "    flatten = Flatten()(pool3)\n",
    "    # add a fully connected layer to classify the images\n",
    "    class1 = Dense(64, activation='relu')(flatten)\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)\n",
    "\n",
    "    # flatten the output from the convolutional layers\n",
    "    flatten = Flatten()(pool3)\n",
    "    # add a fully connected layer to classify the images\n",
    "    regress1 = Dense(64, activation='relu')(flatten)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "\n",
    "    # Create a model using the Model() function and specifying the input and output layers\n",
    "    model = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training The Model Using The Fit() Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 21:35:04.459682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1240]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-09 21:35:04.459983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [1240]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 397ms/step - loss: 2.1223 - dense_5_loss: 1.3823 - dense_7_loss: 0.7400 - dense_5_accuracy: 0.2500 - dense_5_mse: 0.4565 - dense_7_accuracy: 0.1250 - dense_7_mse: 0.2045 - val_loss: 1.7140 - val_dense_5_loss: 0.9987 - val_dense_7_loss: 0.7154 - val_dense_5_accuracy: 0.2500 - val_dense_5_mse: 0.3922 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.1774\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.3175 - dense_5_loss: 0.7145 - dense_7_loss: 0.6031 - dense_5_accuracy: 0.5000 - dense_5_mse: 0.2599 - dense_7_accuracy: 0.3750 - dense_7_mse: 0.1518 - val_loss: 1.3101 - val_dense_5_loss: 0.6490 - val_dense_7_loss: 0.6612 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2280 - val_dense_7_accuracy: 0.5000 - val_dense_7_mse: 0.1596\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 1.2356 - dense_5_loss: 0.6887 - dense_7_loss: 0.5469 - dense_5_accuracy: 0.5000 - dense_5_mse: 0.2478 - dense_7_accuracy: 0.5000 - dense_7_mse: 0.1233 - val_loss: 1.4411 - val_dense_5_loss: 0.6457 - val_dense_7_loss: 0.7954 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2263 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.2172\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.2158 - dense_5_loss: 0.6876 - dense_7_loss: 0.5282 - dense_5_accuracy: 0.5000 - dense_5_mse: 0.2473 - dense_7_accuracy: 0.3750 - dense_7_mse: 0.1118 - val_loss: 1.6484 - val_dense_5_loss: 0.6648 - val_dense_7_loss: 0.9836 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2358 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.2658\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 1.1410 - dense_5_loss: 0.6636 - dense_7_loss: 0.4775 - dense_5_accuracy: 0.6250 - dense_5_mse: 0.2353 - dense_7_accuracy: 0.3750 - dense_7_mse: 0.0938 - val_loss: 1.4937 - val_dense_5_loss: 0.6464 - val_dense_7_loss: 0.8473 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2267 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.2221\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 1.0730 - dense_5_loss: 0.6439 - dense_7_loss: 0.4291 - dense_5_accuracy: 0.6250 - dense_5_mse: 0.2256 - dense_7_accuracy: 0.3750 - dense_7_mse: 0.0755 - val_loss: 1.4798 - val_dense_5_loss: 0.6428 - val_dense_7_loss: 0.8371 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2249 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.2149\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.0371 - dense_5_loss: 0.6330 - dense_7_loss: 0.4040 - dense_5_accuracy: 0.6250 - dense_5_mse: 0.2205 - dense_7_accuracy: 0.5000 - dense_7_mse: 0.0653 - val_loss: 1.5010 - val_dense_5_loss: 0.6321 - val_dense_7_loss: 0.8688 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2197 - val_dense_7_accuracy: 0.5000 - val_dense_7_mse: 0.2277\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.9322 - dense_5_loss: 0.5865 - dense_7_loss: 0.3457 - dense_5_accuracy: 0.6250 - dense_5_mse: 0.1979 - dense_7_accuracy: 0.5000 - dense_7_mse: 0.0448 - val_loss: 1.6994 - val_dense_5_loss: 0.6404 - val_dense_7_loss: 1.0590 - val_dense_5_accuracy: 0.8750 - val_dense_5_mse: 0.2237 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.2771\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.8677 - dense_5_loss: 0.5470 - dense_7_loss: 0.3207 - dense_5_accuracy: 0.8750 - dense_5_mse: 0.1796 - dense_7_accuracy: 0.3750 - dense_7_mse: 0.0402 - val_loss: 1.7540 - val_dense_5_loss: 0.5981 - val_dense_7_loss: 1.1560 - val_dense_5_accuracy: 0.7500 - val_dense_5_mse: 0.2031 - val_dense_7_accuracy: 0.2500 - val_dense_7_mse: 0.2840\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.7447 - dense_5_loss: 0.4753 - dense_7_loss: 0.2694 - dense_5_accuracy: 0.8750 - dense_5_mse: 0.1475 - dense_7_accuracy: 0.5000 - dense_7_mse: 0.0161 - val_loss: 1.6880 - val_dense_5_loss: 0.6073 - val_dense_7_loss: 1.0807 - val_dense_5_accuracy: 0.8750 - val_dense_5_mse: 0.2076 - val_dense_7_accuracy: 0.5000 - val_dense_7_mse: 0.2675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176f3dd90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = train.as_numpy_iterator().next()\n",
    "x_val, y_val = val.as_numpy_iterator().next()\n",
    "\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=4, epochs=10, validation_data=(x_val, y_val), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 21:35:13.441305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [1320]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-09 21:35:13.441645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [1320]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    }
   ],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    sample_coords = prediction[1][idx]\n",
    "    \n",
    "    if prediction[0][idx] > 0.9:\n",
    "        cv.rectangle(sample_image, \n",
    "                      tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# getting the video from laptop camera \n",
    "# later change to external video camera\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # capture video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # resizes frame size to 450x450\n",
    "    resized_frame = cv.resize(frame, (450, 450))\n",
    "\n",
    "    rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (150,150))\n",
    "\n",
    "    yhat = model.predict(np.expand_dims(resized/255,0)) # no clue if this is right\n",
    "    sample_coords = yhat[1][0]\n",
    "    \n",
    "    if yhat[0] > 0.5: \n",
    "        # Controls the main rectangle\n",
    "        cv.rectangle(frame, \n",
    "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        \n",
    "        # Controls the text rendered\n",
    "        cv.putText(frame, 'face', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('EyeTrack', frame)\n",
    "\n",
    "    # break out of the loop\n",
    "    if cv.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# when done with use - release video\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
